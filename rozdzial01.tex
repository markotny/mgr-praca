% !TeX root = ./Dyplom.tex

\chapter{Wstęp}
 
\section{Cel i zakres pracy}
	Celem pracy jest zbadanie skuteczności nowoczesnych metod z dziedziny przetwarzania języka naturalnego
		w kontekście metod oceny podobieństwa semantycznego na potrzeby analizy dyskursu publicznego.
	Prace przeprowadzone zostaną na zbiorze wypowiedzi posłów Sejmu III Rzeczpospolitej Polskiej pozyskanym z Korpusu Dyskursu Parlamentarnego.
	Ze względu na brak istniejących oznaczeń dokumentów, postanowiono skupić się na problemie z dziedziny uczenia nienadzorowanego, jakim jest modelowanie tematyczne.
	Jest to zadanie, w którym model językowy grupuje podobne dokumenty poprzez analizę semantyczną tworząc zbiory reprezentujące spójne tematy.

	Z wybranym zbiorem dokumentów wiążą się dodatkowe wyzwania, mianowicie nie wszystkie wypowiedzi zawierają wyróżniające słowa
		(np.\ kiedy wypowiedź jest odpowiedzią na zapytanie to osoba nie zawsze zawrze w wypowiedzi kontekst).
	Dodatkowo, większość współczesnych metod NLP operuje na krótkich dokumentach, podczas gdy wypowiedzi sejmowe mają formę nierzadko długich przemówień.
	Te aspekty korpusu oraz wysokie zróżnicowanie tematyczne kwestii poruszanych w sejmie sprawiają,
		że jest to intrygujący i obiecujący zestaw dokumentów do analizy porównawczej.

	Modelowanie tematyczne z wykorzystaniem wektorów kodujących dokumenty odbywa się w czterech krokach:
	\begin{enumerate}
		\item osadzenie wektorów dokumentów,
		\item redukcja wymiarowości wektorów,
		\item grupowanie na podstawie podobieństwa,
		\item utworzenie reprezentacji słownej każdego tematu (zbioru słów najlepiej opisujących zgrupowane wypowiedzi).
	\end{enumerate}
	Krok pierwszy może zostać wykonany każdą metodą generującą wektory kodujące dokumenty na jednej wspólnej przestrzeni.
	W ostatnich latach powstały przełomowe rozwiązania oparte na modelach językowych bazujących na architekturze BERT\@.
	W pracy przeprowadzone zostaną badania mające na celu ustalenie, jak skuteczne są takie modele w kontekście analizowanego problemu.
	Dodatkowo, analiza przeprowadzona zostanie również na modelach wykorzystujących alternatywne podejścia kodowania dokumentów,
		co daje sumarycznie trzy następujące metody:
	\begin{itemize}
		\item architektura BERT,
		\item sieć konwolucyjna,
		\item TF-IDF (metoda statystyczna).
	\end{itemize}
	Ponadto, testy wykonane zostaną dla różnych kombinacji parametrów wykorzystywanych algorytmów do redukcji wymiarowości i grupowania wektorów,
		aby odnaleźć optymalne wartości dla analizowanego korpusu.

	Jako alternatywną metodę modelowania tematycznego dokumentów, która stanowi punkt odniesienia,
		przeprowadzona zostanie analiza modelem LDA\@.
	Jest to obecnie jedno z najpopularniejszych narzędzi przeprowadzania modelowania tematycznego\cite{LDA_popularity},
		które bazuje na metodach statystycznych.

\section{Układ pracy}
	W kolejnym rozdziale omówiony zostanie wykorzystywany korpus wypowiedzi sejmowych,
		oraz działania jakie zostały wykonane podczas jego przetwarzania.
	W rozdziale trzecim przedstawiono wszystkie analizowane metody generowania wektorów dokumentów.
	Rozdział czwarty zawiera opisy kolejnych kroków wykonywanych w ramach modelowania tematycznego
		--- redukcja wymiarowości wektorów, grupowanie oraz generowanie reprezentacji tematu.
	W kolejnym rozdziale przedstawione zostały sposoby ewaluacji tematów odnalezionych w korpusie.
	W szóstym rozdziale opisano uzyskane wyniki zarówno pod kątem wykorzystywanych metod i parametrów, jak i zastosowanych metryk.
	W ostatnim rozdziale zawarto podsumowanie pracy.