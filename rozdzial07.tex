% !TeX root = ./Dyplom.tex

\chapter{Podsumowanie}
	W pracy wykonane zostało kompleksowe porównanie metod kodujących duże i różnorodne dokumenty w wektory zachowując cechy semantyczne tekstu.
	Jako zadanie służące do porównania efektywności modeli językowych wybrano modelowanie tematyczne, które jest problemem uczenia nienadzorowanego.
	Skupiono się na najnowszych algorytmach z tej dziedziny, jednak porównano je również z wiodącą metodą LDA\@.
	Z powodzeniem utworzono modele przewyższające jakością LDA, choć nie wszystkie pierwotne założenia okazały się słuszne.
	Jak pokazała analiza wyników, dokładność zaawansowanych modeli takich jak \emph{Sentence-Transformers} czy \emph{Universal Sentence Encoder}
		maleje dla długich wypowiedzi.
	Okazuje się, że analizując tak długie teksty, lepiej jest skorzystać ze zwykłych metod statystycznych poprzedzonych lematyzacją danych wejściowych.
	Wektory wygenerowane w taki sposób efektywniej wykorzystują duży rozmiar dokumentów,
		podczas gdy pozostałe modele osiągają gorszą dokładność wynikającą z uśredniania wektorów zdań bądź analizy tylko początkowych fragmentów wypowiedzi.
	
	Niemniej wszystkie metody bazujące na algorytmie \emph{BERTopic} wygenerowały tematy o znacznie większej spójności, niż LDA\@.
	Dzięki wykrywaniu nieistotnych dokumentów (szumu) otrzymuje się grupy jedynie tych dokumentów, które zawierają konkretne informacje.
	Algorytm LDA nie zawiera takiego mechanizmu, przez co wszystkie wypowiedzi muszą zostać zgrupowane.
	Problem ten jest uwypuklony dla korpusu dyskursu parlamentarnego, gdy analizujemy wypowiedzi wyrwane z kontekstu.
	
	Wysoce prawdopodobne, że w kontekście innych problemów dokładność wektorów wygenerowanych przez zaawansowane modele językowe da lepsze rezultaty niż \emph{TF-IDF}.
	Takim problemem może być przykładowo analiza wydźwięku (ang.\ \emph{sentiment analysis}), czy asymetryczne wyszukiwanie (porównywanie krótkiego zapytania z długimi wypowiedziami).
	Interesującym rozszerzeniem pracy byłoby połączenie modelu tematycznego z analizą wydźwięku.
	Umożliwiłoby to analizę, jakie ugrupowania polityczne wypowiadają się pozytywnie lub negatywnie na dane tematy.
	Nie jest jednak jasne, w jaki sposób dokonać automatycznej ewaluacji dokładności takich modeli.

	Automatyczna ocena dokładności modeli tematycznych również nie jest bezbłędna i jak pokazały wyniki, obecne metody potrafią oceniać wysoko modele nie dające dobrych wyników.
	Oznacza to, że jedyną w pełni skuteczną metodą ewaluacji tego problemu jest manualna weryfikacja przez człowieka.
	Wykorzystując jednak kombinacje istniejących metryk oraz nowych, stworzonych dla tego korpusu, można dokonać analizy porównawczej modeli.
	Stworzono metrykę dedykowaną do analizowanego korpusu, która zakłada, że dwie występujące po sobie wypowiedzi mają wspólny temat.
	Wciąż należy jednak ręcznie weryfikować uzyskane w ten sposób wyniki.

	\section{Możliwości dalszego usprawnienia modeli}
		W projekcie skorzystano z dostępnych wytrenowanych modeli wielojęzykowych.
		Bardzo możliwe, że wytrenowanie modelu dedykowanego do języka polskiego przyniesie lepsze wyniki.
		Stworzenie zbioru danych treningowych do bezpośredniego wytrenowania modelu \emph{SBERT} nie wydaje się łatwo wykonalne,
			aczkolwiek możliwe jest przekazanie wiedzy z modelu angielskiego na polski.
		Wtedy można by wykorzystać najlepszy polski model wielojęzykowy wg.~rankingu KLEJ\footnote{\url{https://klejbenchmark.com/leaderboard} (dostęp dnia 20 czerwca 2021)} (\emph{XLM-RoBERTa (large) + NKJP}).
		Jest to jednak kosztowne działanie ze względu na rozmiar modelu.
		Obiecującym podejściem jest też analiza dokumentów modelami typu Longformer\cite{Longformer}, które dostosowują modele BERT do znacznie dłuższych sekwencji.
		Nie istnieje jeszcze model w pełni wytrenowany dla języka polskiego, są jednak prowadzone nad tym prace\footnote{\url{https://huggingface.co/clarin-pl/long-former-polish} (dostęp dnia 20 czerwca 2021)}. 

		Duża część korpusu nie została przyporządkowana do tematu co sugeruje, że jest wciąż pole do poprawy
			(lub znaczna część wypowiedzi sejmowych jest nieistotnym szumem, co może świadczyć o jakości debat politycznych).
		Możliwe jest opracowanie modelu, który byłby w stanie wykorzystać to, że dokumenty stanowią formę debaty.
		Należałoby podczas analizowania wypowiedzi wziąć pod uwagę jej kontekst, np.\ poprzednią wypowiedź.
		W ten sposób uniknięto by sytuacji, w których dokument poddany analizie zawiera jedynie odniesienia do punktu obrad (np.\ ,,omawiana ustawa'').
		Model taki mógłby przyjąć strukturę rekurencyjną, gdzie wynik przetwarzania jednego zdania jest również dostępny podczas analizy kolejnego.
		
